{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain pinecone-client tiktoken langchain-community openai spacy sentence-transformers ace_tools pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created: 3\n",
      "Total token count: 926\n"
     ]
    }
   ],
   "source": [
    "# Block 1: Chunking Your Data\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "import json\n",
    "import tiktoken\n",
    "\n",
    "max_tokens = 1000  # Maximum tokens per chunk\n",
    "overlap_tokens = 100  # Tokens to overlap between chunks\n",
    "\n",
    "\n",
    "\n",
    "file_path = \"./data/paragraphs.json\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create Documents from sentences\n",
    "documents = []\n",
    "for paragraph in data:\n",
    "    for sentence in paragraph['sentences']:\n",
    "        doc = Document(\n",
    "            page_content=sentence['text'],\n",
    "            metadata={\n",
    "                \"start\": sentence['start'],\n",
    "                \"end\": sentence['end'],\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "\n",
    "def count_tokens(text, model_name='text-embedding-ada-002'):\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "sentences = []\n",
    "token_count = 0\n",
    "for doc in documents:\n",
    "    text = doc.page_content\n",
    "    tokens = count_tokens(text)\n",
    "    sentences.append({'text': text, 'tokens': tokens, 'metadata': doc.metadata})\n",
    "\n",
    "\n",
    "chunks = []\n",
    "current_chunk = []\n",
    "current_token_count = 0\n",
    "\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    sentence_tokens = sentence['tokens']\n",
    "    if current_token_count + sentence_tokens > max_tokens:\n",
    "        chunk_text = ' '.join([s['text'] for s in current_chunk])\n",
    "        chunk_metadata = {\n",
    "            'start': current_chunk[0]['metadata']['start'],\n",
    "            'end': current_chunk[-1]['metadata']['end'],\n",
    "        }\n",
    "        chunk_doc = Document(page_content=chunk_text, metadata=chunk_metadata)\n",
    "        chunks.append(chunk_doc)\n",
    "\n",
    "        # Start new chunk with overlap\n",
    "        overlap = []\n",
    "        overlap_token_count = 0\n",
    "        i = len(current_chunk) - 1\n",
    "        while i >= 0 and overlap_token_count < overlap_tokens:\n",
    "            overlap.insert(0, current_chunk[i])\n",
    "            overlap_token_count += current_chunk[i]['tokens']\n",
    "            i -= 1\n",
    "        current_chunk = overlap.copy()\n",
    "        current_token_count = overlap_token_count\n",
    "\n",
    "    # Add current sentence to current_chunk\n",
    "    current_chunk.append(sentence)\n",
    "    current_token_count += sentence_tokens\n",
    "\n",
    "if current_chunk:\n",
    "    chunk_text = ' '.join([s['text'] for s in current_chunk])\n",
    "    chunk_metadata = {\n",
    "        'start': current_chunk[0]['metadata']['start'],\n",
    "        'end': current_chunk[-1]['metadata']['end'],\n",
    "    }\n",
    "    chunk_doc = Document(page_content=chunk_text, metadata=chunk_metadata)\n",
    "    chunks.append(chunk_doc)\n",
    "\n",
    "print(f\"Number of chunks created: {len(chunks)}\")\n",
    "print(f\"Total token count: {current_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pinecone client setup complete\n"
     ]
    }
   ],
   "source": [
    "# Block 2.1: Setting Up Pinecone with the simplified setup\n",
    "\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index_name = \"chatbot\"\n",
    "pinecone_index = pc.Index(index_name)\n",
    "\n",
    "print(\"pinecone client setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully inserted into Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# Block 2.2: Embed and upsert data into Pinecone\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# create batch embeddings\n",
    "batch_size = 100 \n",
    "all_embeddings = []\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "texts = [chunk.page_content for chunk in chunks]\n",
    "metadatas = [chunk.metadata for chunk in chunks]\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i+batch_size]\n",
    "    batch_embeddings = embeddings.embed_documents(batch_texts)\n",
    "    all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "\n",
    "\n",
    "# Upsert vectors into Pinecone in batches\n",
    "batch_size = 100\n",
    "vectors = []\n",
    "for i, (embedding, metadata) in enumerate(zip(all_embeddings, metadatas)):\n",
    "    vector_id = f\"vec_{i}\"\n",
    "    # Include text and any other necessary metadata\n",
    "    metadata['text'] = texts[i]\n",
    "    vectors.append({'id': vector_id, 'values': embedding, 'metadata': metadata})\n",
    "\n",
    "for i in range(0, len(vectors), batch_size):\n",
    "    batch = vectors[i:i+batch_size]\n",
    "    pinecone_index.upsert(vectors=batch)\n",
    "\n",
    "print(\"Data successfully inserted into Pinecone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\langchain_community\\vectorstores\\pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Block 3: Implementing Retrieval Augmented Generation (RAG)\n",
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "vectorstore = Pinecone(pinecone_index, embeddings.embed_query, \"text\")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "The answer should be short, concise and directly related to the question and not contain filler words. \n",
    "Given the following information, answer the question. \n",
    "Use the information from the documents to support your answer. \n",
    "Do not use any external information or make up any information. \n",
    "If you don't know the answer, write \"I don't know\".\n",
    "\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # You can also try \"map_reduce\" or \"refine\" if needed\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: To get your first SaaS customer, start by validating your product idea with a landing page to capture emails and gauge interest. Engage in customer development by discussing your idea publicly and gathering feedback. Leverage your network or online communities to promote your product. Once you have an email list, launch to them with exclusive offers to convert them into customers. Consider using platforms like Product Hunt or Reddit for additional exposure.\n",
      "\n",
      "\n",
      "---------------------------------------------------------\n",
      "Text: In this video, I'm talking about how to get your first 100 customers for your SaaS product. I'm gonna be offering up actionable strategies and tactics on how you can get this done. I'm Rob Walling. I'\n",
      "Metadata: {'end': 219.455, 'start': 0.08}\n",
      "---\n",
      "Text: And what this does is allows you to build that email launch list which not only provides some validation that people are interested in the value that you're talking about, but it allows you to do what\n",
      "Metadata: {'end': 417.705, 'start': 198.88}\n",
      "---\n",
      "Text: So product hunt launch for example, if you go to youtube.com/microconf, search for product hunt, you'll find that we have an entire 30 minute video on how to do a product hunt launch, and it is an int\n",
      "Metadata: {'end': 593.72, 'start': 383.275}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "How can i get my first saas customer?\n",
    "\"\"\"\n",
    "\n",
    "result = qa_chain(query)\n",
    "print(\"Answer:\", result['result'])\n",
    "\n",
    "print(\"\\n\\n---------------------------------------------------------\")\n",
    "for doc in result['source_documents']:\n",
    "    print(f\"Text: {doc.page_content[:200]}\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    # print(f\"Metadata: {doc}\")\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"score\": 0.5243916511535645,\n",
      "    \"start\": 45.145,\n",
      "    \"end\": 59.13\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.5377623438835144,\n",
      "    \"start\": 383.275,\n",
      "    \"end\": 401.5\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.5429914593696594,\n",
      "    \"start\": 479.71002,\n",
      "    \"end\": 484.99002\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.5434920191764832,\n",
      "    \"start\": 383.275,\n",
      "    \"end\": 401.5\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.5550068020820618,\n",
      "    \"start\": 513.15,\n",
      "    \"end\": 521.165\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.5632674694061279,\n",
      "    \"start\": 479.71002,\n",
      "    \"end\": 484.99002\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.6074326634407043,\n",
      "    \"start\": 260.55,\n",
      "    \"end\": 272.83502\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.6269683837890625,\n",
      "    \"start\": 260.55,\n",
      "    \"end\": 272.83502\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.6328544616699219,\n",
      "    \"start\": 479.71002,\n",
      "    \"end\": 484.99002\n",
      "  },\n",
      "  {\n",
      "    \"score\": 0.6492415070533752,\n",
      "    \"start\": 293.945,\n",
      "    \"end\": 299.945\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from IPython.display import display  # For displaying dataframes in Jupyter\n",
    "import torch\n",
    "import re\n",
    "\n",
    "# Load the sentence transformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')  # Upgraded model\n",
    "\n",
    "# Load paragraphs.json\n",
    "with open('./data/paragraphs.json', 'r', encoding='utf-8') as json_file:\n",
    "    paragraphs = json.load(json_file)\n",
    "\n",
    "# Extract sentences and their timestamps from paragraphs.json\n",
    "text_sentences = []\n",
    "timestamps = []\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    for sentence in paragraph['sentences']:\n",
    "        text_sentences.append(sentence['text'])\n",
    "        timestamps.append((sentence['start'], sentence['end']))\n",
    "\n",
    "# Assuming 'result' contains the answer text that you want to find matches for\n",
    "answer = result['result']\n",
    "\n",
    "# Split the answer into sentences using a simple regex-based approach\n",
    "def split_into_sentences(text):\n",
    "    # This splits on punctuation that usually ends a sentence followed by space\n",
    "    return re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "# Split the answer into sentences\n",
    "answer_sentences = split_into_sentences(answer)\n",
    "\n",
    "# Encode sentences from the text once\n",
    "text_embeddings = model.encode(text_sentences, convert_to_tensor=True)\n",
    "\n",
    "# Prepare a list to hold all matching results\n",
    "all_matches = []\n",
    "\n",
    "# For each sentence in the answer, find the top 3 most similar sentences in the text\n",
    "for ans_sentence in answer_sentences:\n",
    "    ans_embedding = model.encode(ans_sentence, convert_to_tensor=True)\n",
    "    # Compute cosine similarities between the answer sentence and all text sentences\n",
    "    cosine_scores = util.cos_sim(ans_embedding, text_embeddings)[0]\n",
    "    # Get the top 3 matches\n",
    "    top_results = torch.topk(cosine_scores, k=3)\n",
    "    for idx, score in zip(top_results.indices, top_results.values):\n",
    "        all_matches.append({\n",
    "            # 'matched': text_sentences[idx],\n",
    "            'score': score.item(),\n",
    "            'start': timestamps[idx][0],\n",
    "            'end': timestamps[idx][1]\n",
    "        })\n",
    "\n",
    "# # Convert the matches into a DataFrame and sort by similarity score\n",
    "# matching_data = pd.DataFrame(all_matches)\n",
    "# matching_data = matching_data.sort_values(by='score', ascending=False)\n",
    "\n",
    "# # Limit the results to top 10\n",
    "# matching_data = matching_data.head(10)\n",
    "\n",
    "# # Display the DataFrame in the notebook\n",
    "# display(matching_data)\n",
    "\n",
    "\n",
    "all_matches = sorted(all_matches, key=lambda x: x['score'])\n",
    "top_matches = all_matches[:10]\n",
    "top_matches_json = json.dumps(top_matches, indent=2)\n",
    "print(top_matches_json)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
