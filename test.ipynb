{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -Q\n"
     ]
    }
   ],
   "source": [
    "!pip install -Q --upgrade langchain pinecone-client tiktoken langchain-community openai spacy sentence-transformers ace_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "  File \"C:\\Users\\Me\\AppData\\Local\\Temp\\ipykernel_28244\\85282502.py\", line 3, in <module>\n",
      "    from langchain.docstore.document import Document\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\langchain\\__init__.py\", line 11, in <module>\n",
      "    __version__ = metadata.version(__package__)\n",
      "  File \"C:\\Users\\Me\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\metadata.py\", line 569, in version\n",
      "    return distribution(distribution_name).version\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 508, in version\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 482, in metadata\n",
      "ImportError: cannot import name '_adapters' from 'importlib_metadata' (c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\importlib_metadata\\__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\pygments\\styles\\__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1114, in get_records\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\pygments\\styles\\__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "# Block 1: Chunking Your Data\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "import json\n",
    "import tiktoken\n",
    "import os\n",
    "\n",
    "# Load your data from the JSON file\n",
    "data_folder = \"./data\"\n",
    "json_file = \"paragraphs.json\"\n",
    "file_path = os.path.join(data_folder, json_file)\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create Documents from sentences\n",
    "documents = []\n",
    "for paragraph in data:\n",
    "    for sentence in paragraph['sentences']:\n",
    "        doc = Document(\n",
    "            page_content=sentence['text'],\n",
    "            metadata={\n",
    "                \"start\": sentence['start'],\n",
    "                \"end\": sentence['end'],\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "\n",
    "# Function to count tokens using tiktoken\n",
    "def count_tokens(text, model_name='text-embedding-ada-002'):\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "# Prepare sentences with token counts and metadata\n",
    "sentences = []\n",
    "for doc in documents:\n",
    "    text = doc.page_content\n",
    "    tokens = count_tokens(text)\n",
    "    sentences.append({'text': text, 'tokens': tokens, 'metadata': doc.metadata})\n",
    "\n",
    "# Set maximum tokens per chunk and overlap tokens\n",
    "max_tokens = 1000  # Maximum tokens per chunk\n",
    "overlap_tokens = 100  # Tokens to overlap between chunks\n",
    "\n",
    "# Group sentences into chunks\n",
    "chunks = []\n",
    "current_chunk = []\n",
    "current_token_count = 0\n",
    "\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    sentence_tokens = sentence['tokens']\n",
    "    if current_token_count + sentence_tokens > max_tokens:\n",
    "        # Create chunk\n",
    "        chunk_text = ' '.join([s['text'] for s in current_chunk])\n",
    "        chunk_metadata = {\n",
    "            'start': current_chunk[0]['metadata']['start'],\n",
    "            'end': current_chunk[-1]['metadata']['end'],\n",
    "        }\n",
    "        chunk_doc = Document(page_content=chunk_text, metadata=chunk_metadata)\n",
    "        chunks.append(chunk_doc)\n",
    "\n",
    "        # Start new chunk with overlap\n",
    "        overlap = []\n",
    "        overlap_token_count = 0\n",
    "        i = len(current_chunk) - 1\n",
    "        while i >= 0 and overlap_token_count < overlap_tokens:\n",
    "            overlap.insert(0, current_chunk[i])\n",
    "            overlap_token_count += current_chunk[i]['tokens']\n",
    "            i -= 1\n",
    "        current_chunk = overlap.copy()\n",
    "        current_token_count = overlap_token_count\n",
    "\n",
    "    # Add current sentence to current_chunk\n",
    "    current_chunk.append(sentence)\n",
    "    current_token_count += sentence_tokens\n",
    "\n",
    "# Add any remaining sentences as a chunk\n",
    "if current_chunk:\n",
    "    chunk_text = ' '.join([s['text'] for s in current_chunk])\n",
    "    chunk_metadata = {\n",
    "        'start': current_chunk[0]['metadata']['start'],\n",
    "        'end': current_chunk[-1]['metadata']['end'],\n",
    "    }\n",
    "    chunk_doc = Document(page_content=chunk_text, metadata=chunk_metadata)\n",
    "    chunks.append(chunk_doc)\n",
    "\n",
    "print(f\"Number of chunks created: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully inserted into Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# Block 2: Setting Up Pinecone and Inserting Data\n",
    "\n",
    "# Generate embeddings for the chunks\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "\n",
    "# Extract texts and metadata from chunks\n",
    "texts = [chunk.page_content for chunk in chunks]\n",
    "metadatas = [chunk.metadata for chunk in chunks]\n",
    "\n",
    "# Generate embeddings in batches\n",
    "batch_size = 100  # Adjust based on your preference\n",
    "all_embeddings = []\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i+batch_size]\n",
    "    batch_embeddings = embeddings.embed_documents(batch_texts)\n",
    "    all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "index_name = \"chatbot\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Prepare vectors for upsert\n",
    "vectors = []\n",
    "for i, (embedding, metadata) in enumerate(zip(all_embeddings, metadatas)):\n",
    "    vector_id = f\"vec_{i}\"\n",
    "    # Include text and any other necessary metadata\n",
    "    metadata['text'] = texts[i]\n",
    "    vectors.append({'id': vector_id, 'values': embedding, 'metadata': metadata})\n",
    "\n",
    "# Upsert vectors into Pinecone in batches\n",
    "batch_size = 100  # Adjust based on your preference\n",
    "for i in range(0, len(vectors), batch_size):\n",
    "    batch = vectors[i:i+batch_size]\n",
    "    index.upsert(vectors=batch)\n",
    "\n",
    "print(\"Data successfully inserted into Pinecone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n",
      "  File \"C:\\Users\\Me\\AppData\\Local\\Temp\\ipykernel_28244\\1688721633.py\", line 4, in <module>\n",
      "    from langchain.vectorstores import Pinecone\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\langchain\\__init__.py\", line 8, in <module>\n",
      "    from langchain_core._api.deprecation import surface_langchain_deprecation_warnings\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\langchain_core\\__init__.py\", line 19, in <module>\n",
      "    __version__ = metadata.version(__package__)\n",
      "  File \"C:\\Users\\Me\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\metadata.py\", line 569, in version\n",
      "    return distribution(distribution_name).version\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 508, in version\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\importlib_metadata\\__init__.py\", line 482, in metadata\n",
      "ImportError: cannot import name '_adapters' from 'importlib_metadata' (c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\importlib_metadata\\__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\pygments\\styles\\__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1114, in get_records\n",
      "  File \"c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\pygments\\styles\\__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "# Block 3: Implementing Retrieval Augmented Generation (RAG)\n",
    "\n",
    "# Set up the retriever using LangChain's Pinecone integration\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "\n",
    "# Use the same index and embeddings as before\n",
    "vectorstore = Pinecone(index, embeddings.embed_query, \"text\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Set up the language model and prompt\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define the prompt template\n",
    "template = \"\"\"\n",
    "The answer should be short, concise and directly related to the question and not contain filler words. \n",
    "Given the following information, answer the question. \n",
    "Use the information from the documents to support your answer. \n",
    "Do not use any external information or make up any information. \n",
    "If you don't know the answer, write \"I don't know\".\n",
    "\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # You can also try \"map_reduce\" or \"refine\" if needed\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "query = \"How can i get my first saas customer?\"\n",
    "\n",
    "# Get the answer\n",
    "result = qa_chain(query)\n",
    "\n",
    "# Print the answer\n",
    "print(\"Answer:\", result['result'])\n",
    "\n",
    "# Optionally, print the source documents\n",
    "print(\"\\nSource Documents:\")\n",
    "for doc in result['source_documents']:\n",
    "    print(f\"Text: {doc.page_content}\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(f\"Metadata: {doc}\")\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this video, I'm talking about how to get your first 100 customers for your SaaS product. I'm gonn\n"
     ]
    }
   ],
   "source": [
    "answer = result['result']\n",
    "with open('./data/large-data.txt', 'r', encoding='utf-8') as file:\n",
    "    data = file.read()\n",
    "\n",
    "text = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  pip install [options] [-e] <vcs project url> ...\n",
      "  pip install [options] [-e] <local project path> ...\n",
      "  pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -Q\n"
     ]
    }
   ],
   "source": [
    "!pip install -Q spacy sentence-transformers ace_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\Scripts\\python.exe: No module named -Q\n"
     ]
    }
   ],
   "source": [
    "!python -m -Q spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Me\\Desktop\\chat-with-audio\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer Sentence</th>\n",
       "      <th>Matched Sentence</th>\n",
       "      <th>Similarity Score</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To get your first SaaS customer, start by vali...</td>\n",
       "      <td>You look at the most common b to b SaaS market...</td>\n",
       "      <td>0.672609</td>\n",
       "      <td>487.550020</td>\n",
       "      <td>495.83500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Leverage your network or online communities to...</td>\n",
       "      <td>I would recommend going on social media, podca...</td>\n",
       "      <td>0.662606</td>\n",
       "      <td>260.550000</td>\n",
       "      <td>272.83502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To get your first SaaS customer, start by vali...</td>\n",
       "      <td>If you don't, I would not invest the time to b...</td>\n",
       "      <td>0.659703</td>\n",
       "      <td>91.799995</td>\n",
       "      <td>96.50500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To get your first SaaS customer, start by vali...</td>\n",
       "      <td>However, building and selling a SaaS product, ...</td>\n",
       "      <td>0.655780</td>\n",
       "      <td>81.560000</td>\n",
       "      <td>87.88000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Consider using platforms like Product Hunt or ...</td>\n",
       "      <td>I would recommend going on social media, podca...</td>\n",
       "      <td>0.626968</td>\n",
       "      <td>260.550000</td>\n",
       "      <td>272.83502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Once you have interested leads, launch to your...</td>\n",
       "      <td>And the idea is that that email launch list ge...</td>\n",
       "      <td>0.618134</td>\n",
       "      <td>324.205020</td>\n",
       "      <td>329.96500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Once you have interested leads, launch to your...</td>\n",
       "      <td>And what this does is allows you to build that...</td>\n",
       "      <td>0.602901</td>\n",
       "      <td>198.880000</td>\n",
       "      <td>212.17500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Engage in customer development by discussing y...</td>\n",
       "      <td>I would recommend going on social media, podca...</td>\n",
       "      <td>0.601353</td>\n",
       "      <td>260.550000</td>\n",
       "      <td>272.83502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Once you have interested leads, launch to your...</td>\n",
       "      <td>So let's say you followed this advice and you ...</td>\n",
       "      <td>0.578584</td>\n",
       "      <td>284.130000</td>\n",
       "      <td>288.55002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Engage in customer development by discussing y...</td>\n",
       "      <td>How do I find usually one marketing approach t...</td>\n",
       "      <td>0.559224</td>\n",
       "      <td>479.710020</td>\n",
       "      <td>484.99002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Answer Sentence  \\\n",
       "0   To get your first SaaS customer, start by vali...   \n",
       "6   Leverage your network or online communities to...   \n",
       "1   To get your first SaaS customer, start by vali...   \n",
       "2   To get your first SaaS customer, start by vali...   \n",
       "12  Consider using platforms like Product Hunt or ...   \n",
       "9   Once you have interested leads, launch to your...   \n",
       "10  Once you have interested leads, launch to your...   \n",
       "3   Engage in customer development by discussing y...   \n",
       "11  Once you have interested leads, launch to your...   \n",
       "4   Engage in customer development by discussing y...   \n",
       "\n",
       "                                     Matched Sentence  Similarity Score  \\\n",
       "0   You look at the most common b to b SaaS market...          0.672609   \n",
       "6   I would recommend going on social media, podca...          0.662606   \n",
       "1   If you don't, I would not invest the time to b...          0.659703   \n",
       "2   However, building and selling a SaaS product, ...          0.655780   \n",
       "12  I would recommend going on social media, podca...          0.626968   \n",
       "9   And the idea is that that email launch list ge...          0.618134   \n",
       "10  And what this does is allows you to build that...          0.602901   \n",
       "3   I would recommend going on social media, podca...          0.601353   \n",
       "11  So let's say you followed this advice and you ...          0.578584   \n",
       "4   How do I find usually one marketing approach t...          0.559224   \n",
       "\n",
       "    Start Time   End Time  \n",
       "0   487.550020  495.83500  \n",
       "6   260.550000  272.83502  \n",
       "1    91.799995   96.50500  \n",
       "2    81.560000   87.88000  \n",
       "12  260.550000  272.83502  \n",
       "9   324.205020  329.96500  \n",
       "10  198.880000  212.17500  \n",
       "3   260.550000  272.83502  \n",
       "11  284.130000  288.55002  \n",
       "4   479.710020  484.99002  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "from IPython.display import display  # For displaying dataframes in Jupyter\n",
    "import torch\n",
    "import re\n",
    "\n",
    "# Load the sentence transformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')  # Upgraded model\n",
    "\n",
    "# Load paragraphs.json\n",
    "with open('./data/paragraphs.json', 'r', encoding='utf-8') as json_file:\n",
    "    paragraphs = json.load(json_file)\n",
    "\n",
    "# Extract sentences and their timestamps from paragraphs.json\n",
    "text_sentences = []\n",
    "timestamps = []\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    for sentence in paragraph['sentences']:\n",
    "        text_sentences.append(sentence['text'])\n",
    "        timestamps.append((sentence['start'], sentence['end']))\n",
    "\n",
    "# Assuming 'result' contains the answer text that you want to find matches for\n",
    "answer = result['result']\n",
    "\n",
    "# Split the answer into sentences using a simple regex-based approach\n",
    "def split_into_sentences(text):\n",
    "    # This splits on punctuation that usually ends a sentence followed by space\n",
    "    return re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "# Split the answer into sentences\n",
    "answer_sentences = split_into_sentences(answer)\n",
    "\n",
    "# Encode sentences from the text once\n",
    "text_embeddings = model.encode(text_sentences, convert_to_tensor=True)\n",
    "\n",
    "# Prepare a list to hold all matching results\n",
    "all_matches = []\n",
    "\n",
    "# For each sentence in the answer, find the top 3 most similar sentences in the text\n",
    "for ans_sentence in answer_sentences:\n",
    "    ans_embedding = model.encode(ans_sentence, convert_to_tensor=True)\n",
    "    # Compute cosine similarities between the answer sentence and all text sentences\n",
    "    cosine_scores = util.cos_sim(ans_embedding, text_embeddings)[0]\n",
    "    # Get the top 3 matches\n",
    "    top_results = torch.topk(cosine_scores, k=3)\n",
    "    for idx, score in zip(top_results.indices, top_results.values):\n",
    "        all_matches.append({\n",
    "            'Answer Sentence': ans_sentence,\n",
    "            'Matched Sentence': text_sentences[idx],\n",
    "            'Similarity Score': score.item(),\n",
    "            'Start Time': timestamps[idx][0],\n",
    "            'End Time': timestamps[idx][1]\n",
    "        })\n",
    "\n",
    "# Convert the matches into a DataFrame and sort by similarity score\n",
    "matching_data = pd.DataFrame(all_matches)\n",
    "matching_data = matching_data.sort_values(by='Similarity Score', ascending=False)\n",
    "\n",
    "# Limit the results to top 10\n",
    "matching_data = matching_data.head(10)\n",
    "\n",
    "# Display the DataFrame in the notebook\n",
    "display(matching_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
